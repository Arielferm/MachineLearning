# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U7pC9-djRGpDOp3KRGytsxHa5WfTaCF8

# KNN

Pasos:



1. IMPORTACI√ìN DE LIBRERIA:



```
# from sklearn.neighbors import KNeighborsClassifier
```

https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html

2. Cargamos en X los valores de las features y en Y los valores de la variable a predecir.



```
X = data[['feature1', 'feature2', 'feature3', 'feature4', 'feature5']]
y = data['target']
```

3. Aplicamos el modelo y fiteamos en la data

```
k=3 (ejemplo)

knn = KNeighborsClassifier(n_neighbors=k)

knn.fit(X, y)

```

4. Predecimos sobre un conjunto nuevo de X

```
prediction=knn.predict(X_sin_etiquetar)
```

# Ejemplo
"""

from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt

x = [4, 5, 10, 4, 3, 11, 14 , 8, 10, 12]
y = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]
classes = [0, 0, 1, 0, 0, 1, 1, 0, 1, 1]

data = list(zip(x, y))
print(data)

knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(data, classes)

new_x = 8
new_y = 21
new_point = [(new_x, new_y)]
prediction = knn.predict(new_point)
print(prediction)

plt.scatter(x + [new_x], y + [new_y], c=classes + [prediction[0]])
plt.text(x=new_x-1.7, y=new_y-0.7, s=f"new point, class: {prediction[0]}")
plt.show()

"""## Con un data set"""

import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
# datos ficticios
np.random.seed(42)


num_samples = 1000
features = np.random.rand(num_samples, 3)  # 3 caracter√≠sticas predictoras
target = np.random.choice([0, 1, 2], size=num_samples)


df = pd.DataFrame(features, columns=['Feature1', 'Feature2', 'Feature3'])
df['Target'] = target


# MODELAMOS

k = 5  # N√∫mero de vecinos a considerar
knn_classifier = KNeighborsClassifier(n_neighbors=k)


knn_classifier.fit(df[['Feature1', 'Feature2', 'Feature3']], df['Target'])


# PREDECIMOS
new_data = pd.DataFrame(np.random.rand(10, 3), columns=['Feature1', 'Feature2', 'Feature3'])


predicted_labels = knn_classifier.predict(new_data)


print("Predicciones para los datos desconocidos:")
print(predicted_labels)

# Hacer predicciones en los mismos datos de entrenamiento
y_pred_train = knn_classifier.predict(df[['Feature1', 'Feature2', 'Feature3']])

# Calcular la precisi√≥n del modelo en los datos de entrenamiento
accuracy_train = np.mean(y_pred_train == df['Target'])
print("Precisi√≥n del modelo KNN en datos de entrenamiento:", accuracy_train)

"""# Ejemplo con evaluaci√≥n de n¬∞ de k"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score, KFold, cross_val_predict
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score
import seaborn as sns

# Cargar el conjunto de datos
iris = load_iris()
X = iris.data
y = iris.target

# Definir los valores de k para la validaci√≥n cruzada k-fold
k_values = range(2, 11)  # Probaremos k desde 2 hasta 10

# Lista para almacenar los puntajes de validaci√≥n cruzada promedio para cada valor de k
mean_scores = []

# Realizar validaci√≥n cruzada k-fold para cada valor de k
for k in k_values:
    # Crear un clasificador KNN con el valor de k actual
    knn = KNeighborsClassifier(n_neighbors=k)

    # Realizar validaci√≥n cruzada k-fold
    kfold = KFold(n_splits=5, shuffle=True, random_state=42)  # Usamos 5 pliegues
    scores = cross_val_score(knn, X, y, cv=kfold)

    # Calcular el puntaje medio de la validaci√≥n cruzada
    mean_score = np.mean(scores)
    mean_scores.append(mean_score)

    # Imprimir los puntajes de cada pliegue y el promedio
    print(f'k={k}: Puntajes de cada pliegue={scores}, Puntaje promedio={mean_score:.4f}')

# Identificar el mejor valor de k
best_k = k_values[np.argmax(mean_scores)]
best_score = max(mean_scores)
print(f'\nEl mejor valor de k es {best_k} con un puntaje promedio de {best_score:.4f}')

# Entrenar el modelo con el mejor valor de k y predecir usando validaci√≥n cruzada
knn = KNeighborsClassifier(n_neighbors=best_k)
y_pred = cross_val_predict(knn, X, y, cv=5)

# Generar el reporte de clasificaci√≥n
print("\nReporte de Clasificaci√≥n:")
print(classification_report(y, y_pred))

# Mostrar la matriz de confusi√≥n
print("\nMatriz de Confusi√≥n:")
cm = confusion_matrix(y, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Matriz de Confusi√≥n')
plt.show()

# Si es un problema de clasificaci√≥n binaria, podemos graficar la curva ROC y calcular el AUC
if len(np.unique(y)) == 2:
    y_prob = cross_val_predict(knn, X, y, cv=5, method='predict_proba')
    fpr, tpr, _ = roc_curve(y, y_prob[:, 1], pos_label=1)
    auc = roc_auc_score(y, y_prob[:, 1])

    plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend(loc='best')
    plt.show()

"""Validaci√≥n Cruzada K-Fold
La validaci√≥n cruzada k-fold divide el conjunto de datos en
ùëò subconjuntos (o "pliegues") de tama√±o aproximadamente igual. Luego, el proceso de entrenamiento y evaluaci√≥n se repite
ùëò
k veces, utilizando un pliegue diferente como conjunto de prueba en cada iteraci√≥n y los
ùëò
‚àí
1
k‚àí1 pliegues restantes como conjunto de entrenamiento. Al final, los resultados de las
ùëò
k evaluaciones se promedian para obtener una estimaci√≥n del rendimiento del modelo.



Interpretaci√≥n de los Resultados

* Reporte de Clasificaci√≥n: https://medium.com/@chanakapinfo/classification-report-explained-precision-recall-accuracy-macro-average-and-weighted-average-8cd358ee2f8a
"""

